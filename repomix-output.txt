This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-11-28T21:11:02.976Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
.gitignore
iros/assets/__init__.py
iros/coords.py
iros/images.py
iros/io.py
iros/mask.py
iros/utils.py
package.json
pyproject.toml
README.md
tests/test_image_composition.py
tests/test_mask_camera.py

================================================================
Repository Files
================================================================

================
File: .gitignore
================
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
.idea/

================
File: iros/assets/__init__.py
================
from pathlib import (
    Path,
)

path_wfm_mask = Path(__file__).parent / "wfm_mask.fits"

================
File: iros/coords.py
================
import numpy as np


def get_rotation_matrices(
        pointing_radec_z: tuple[float, float] | np.array,
        pointing_radec_x: tuple[float, float] | np.array,
) -> tuple[np.array, np.array]:
    """
    Calculates rotation matrices between Earth equatorial and camera reference frames.

    This function computes two 3x3 rotation matrices that transform coordinates between
    the Earth equatorial reference frame (RA/Dec) and the camera's local reference frame.
    The transformation is defined by specifying the camera's z-axis and x-axis directions
    in equatorial coordinates.

    Args:
        pointing_radec_z: Camera's z-axis direction in equatorial coordinates.
            Either tuple[float, float] or np.array of (RA, Dec) in degrees.
            RA in [0, 360], Dec in [-90, 90].
        pointing_radec_x: Camera's x-axis direction in equatorial coordinates.
            Either tuple[float, float] or np.array of (RA, Dec) in degrees.
            RA in [0, 360], Dec in [-90, 90].

    Returns:
        tuple[np.ndarray, np.ndarray]: A tuple containing:
            - rotmat_sky2cam (np.ndarray): 3x3 rotation matrix to transform vectors
              from equatorial to camera coordinates
            - rotmat_cam2sky (np.ndarray): 3x3 rotation matrix to transform vectors
              from camera to equatorial coordinates (transpose of rotmat_sky2cam)

    Notes:
        - The rotation matrices are orthogonal, so rotmat_cam2sky is the transpose
          of rotmat_sky2cam
        - The x and z axes provided must be approximately perpendicular for the
          resulting transformation to be valid
        - The matrices operate on vectors in Cartesian coordinates, not directly
          on RA/Dec angles
        - All internal angle calculations are performed in radians
    """
    ra_z, dec_z = pointing_radec_z
    ra_x, dec_x = pointing_radec_x

    theta_z = np.deg2rad(90 - dec_z)
    phi_z = np.deg2rad(ra_z)

    theta_x = np.deg2rad(90 - dec_x)
    phi_x = np.deg2rad(ra_x)

    sin_theta_x = np.sin(theta_x)
    x_axis = np.array([
        sin_theta_x * np.cos(phi_x),
        sin_theta_x * np.sin(phi_x),
        np.cos(theta_x)
    ])

    sin_theta_z = np.sin(theta_z)
    z_axis = np.array([
        sin_theta_z * np.cos(phi_z),
        sin_theta_z * np.sin(phi_z),
        np.cos(theta_z)
    ])

    y_axis = np.array([
        z_axis[1] * x_axis[2] - z_axis[2] * x_axis[1],
        z_axis[2] * x_axis[0] - z_axis[0] * x_axis[2],
        z_axis[0] * x_axis[1] - z_axis[1] * x_axis[0],
    ])

    rotmat_sky2cam = np.vstack((x_axis, y_axis, z_axis))
    rotmat_cam2sky = rotmat_sky2cam.T

    return rotmat_sky2cam, rotmat_cam2sky


def to_sky_coordinates(
        midpoints_xs: np.array,
        midpoints_ys: np.array,
        pointing_radec_z: tuple[float, float],
        pointing_radec_x: tuple[float, float],
        distance_detector_mask: float,
) -> tuple[np.array, np.array]:
    """
    Converts detector plane coordinates to equatorial sky coordinates (RA/Dec).

    This function performs a coordinate transformation from a rectangular grid of points
    on a detector/mask plane to their corresponding positions in the sky using equatorial
    coordinates. To achieve the transformation it requires the pointings in equatorial
    cooridnates of the x and z axis of the camera.

    The transformation process involves:
    1. Converting detector plane coordinates to direction vectors
    2. Applying the appropriate rotation matrices for the pointing direction
    3. Converting the rotated vectors to spherical coordinates (RA/Dec)

    Args:
        midpoints_xs (np.array): X coordinates of the grid points on the detector plane in spatial units
            (e.g., mm or cm). Shape and dimension should match midpoints_ys.
        midpoints_ys (np.array): Y coordinates of the grid points on the detector plane in spatial units
            (e.g., mm or cm). Shape and dimension should match midpoints_xs.
        pointing_radec_z (tuple[float, float]): Pointing direction of the detector's z-axis in
            (RA, Dec) coordinates in degrees.
        pointing_radec_x (tuple[float, float]): Pointing direction of the detector's x-axis in
            (RA, Dec) coordinates in degrees. Used to define the detector's roll angle.
        distance_detector_mask (float): Distance between the detector and mask planes in the same
            spatial units as midpoints_xs and midpoints_ys.

    Returns:
        tuple[np.array, np.array]: A tuple containing:
            - declinations (np.array): Grid of declination values in degrees, same shape as input arrays
            - right_ascensions (np.array): Grid of right ascension values in degrees, same shape as input arrays.
              Values are in the range [0, 360] degrees.

    Notes:
        - The function assumes a right-handed coordinate system for the detector plane
        - Inputs (midpoints_xs, midpoints_ys,  distance_detector_mask) should be in a consistent unit system
        - The output RA values are normalized to [0, 360) degrees
        - The output Dec values are in the range [-90, 90] degrees
    """
    rotmat_sky2cam, rotmat_cam2sky = get_rotation_matrices(pointing_radec_z, pointing_radec_x,)
    # point distances from the mask center.
    r = np.sqrt(midpoints_xs * midpoints_xs + midpoints_ys * midpoints_ys + distance_detector_mask * distance_detector_mask)
    # these are the versors from the mask center to the detector elements
    versors_local_xs = - midpoints_xs / r
    versors_local_ys = - midpoints_ys / r
    versors_local_zs = distance_detector_mask / r
    # this multiplies all detector vectors with the rotation matrix
    _v = np.hstack(
        (
            versors_local_xs.ravel().reshape(-1, 1, 1),
            versors_local_ys.ravel().reshape(-1, 1, 1),
            versors_local_zs.ravel().reshape(-1, 1, 1),
        )
    )
    versors_eq = np.matmul(rotmat_cam2sky, _v)
    # the versors above are in the rectangular coordinates, we transform into angles
    decs = 0.5 * np.pi - np.arccos(versors_eq[:, 2].ravel())
    ras = np.arctan2(versors_eq[:, 1].ravel(), versors_eq[:, 0].ravel())
    ras[ras < 0] += 2 * np.pi
    decs = np.rad2deg(decs.reshape(midpoints_xs.shape))
    ras = np.rad2deg(ras.reshape(midpoints_ys.shape))
    return decs, ras


def to_angles(
        midpoints_xs: np.array,
        midpoints_ys: np.array,
        distance_detector_mask: float,
) -> tuple[np.array, np.array]:
    """
    Expresses the mask elements in terms of angle between them and the detector center.

    Args:
        midpoints_xs (np.array): X coordinates of the grid points on the detector plane in spatial units
            (e.g., mm or cm). Shape and dimension should match midpoints_ys.
        midpoints_ys (np.array): Y coordinates of the grid points on the detector plane in spatial units
            (e.g., mm or cm). Shape and dimension should match midpoints_xs.
        distance_detector_mask (float): Distance between the detector and mask planes in the same
            spatial units as midpoints_xs and midpoints_ys.


    Returns:
        tuple[np.array, np.array]: A tuple containing:
            - angles_xs (np.array): Angular offsets in the X direction in degrees.
              Negative angles indicate positions left of center. Same shape as input arrays.
            - angles_ys (np.array): Angular offsets in the Y direction in degrees.
              Negative angles indicate positions below center. Same shape as input arrays.
    """
    angles_xs = np.rad2deg(np.arctan(midpoints_xs / distance_detector_mask))
    angles_ys = np.rad2deg(np.arctan(midpoints_ys / distance_detector_mask))
    return angles_xs, angles_ys

================
File: iros/images.py
================
from typing import Callable, Optional

import numpy as np


def compose(a: np.ndarray, b: np.ndarray) -> tuple[np.ndarray, Callable[[int, int], tuple[Optional[tuple[int, int]], Optional[tuple[int, int]]]]]:
    """
    Composes two matrices `a` and `b` into one square embedding.
    The `b` matrix is rotated by 90 degree *clockwise*,
    i.e. np.rot90(b, k=-1) is applied before embedding.

         │
      ───┼──────────────j-index────────────────▶
         │     Δ                       Δ
         │   ◀────▶                  ◀────▶
         │   ┌────┬──────────────────┬────┐  ▲
         │   │    │ N                │    │  │
         │   ├────┼──────────────────┼────┤  │
         │   │    │                  │  E │  │
         │   │    │                  │    │  │
         │   │    │                  │    │  │
     i-index │    │                  │    │maxd
         │   │    │                  │    │  │
         │   │  W │                C │    │  │
         │   ├────┼──────────────────┼────┤  │
         │   │    │                S │    │  │
         │   └────┴──────────────────┴────┘  ▼
         │        ◀───────mind───────▶
         ▼
                        WCE == `a`
                   NCS ==  rotated(`b`)

    Args:
        a (ndarray): First input matrix of shape (n,m) where n < m
        b (ndarray): Second input matrix of same shape as `a`

    Returns:
        Tuple containing:
            - ndarray: The composed square matrix of size maxd x maxd where
                      maxd = max(n,m)
            - Callable: A function f(i,j) that maps positions in the composed matrix
                       to positions in the original matrices a and b. For each position
                       it returns a tuple (pos_a, pos_b) where:
                       - pos_a: Optional tuple (i,j) in matrix a or None if position
                               doesn't map to a
                       - pos_b: Optional tuple (i,j) in matrix b or None if position
                               doesn't map to b

    Raises:
        AssertionError: If matrices a and b have different shapes

    Example:
        >>> a = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])  # 2x4 matrix
        >>> b = np.array([[9, 10, 11, 12], [13, 14, 15, 16]])  # 2x4 matrix

        >>> composed, f = compose(a, b)
        >>> composed.shape
        (4, 4)
        >>> f(1, 1)  # center position
        ((0, 1), (1, 1))  # maps to both a and rotated b
    """
    assert a.shape == b.shape
    maxd, mind = max(a.shape), min(a.shape)
    delta = (maxd - mind) // 2
    a_embedding = np.pad(a, pad_width=((delta, delta), (0, 0)))
    b_embedding = np.pad(np.rot90(b, k=-1), pad_width=((0, 0), (delta, delta)))
    composed = a_embedding + b_embedding

    def _rotb2b(i, j):
        return  mind - 1 - j, i

    def f(i: int, j: int) -> tuple[Optional[tuple[int, int]], Optional[tuple[int, int]]]:
        """
        Given a couple of indeces of the recombined image, returns two couples of
        indeces, one for the `a` matrix, and one for the `b` matrix.

        Args:
            i (int): row index in the composed matrix
            j (int): column index in the composed matrix

        Returns:
            Tuple[Optional[Tuple[int, int]], Optional[Tuple[int, int]]]: A tuple containing
                - First element: Indices (i,j) in matrix a, or None if position doesn't map to a
                - Second element: Indices (i,j) in matrix b, or None if position doesn't map to b

        Raises:
            ValueError: If the position (i,j) is out of bounds of the composed matrix
        """
        if not ((0 <= i < maxd) and (0 <= j < maxd)):
            raise ValueError("position is out of bounds")
        if j < delta:
            # W quadrant
            if not (delta <= i < delta + mind):
                return None, None
            else:
                return (i - delta, j), None
        elif j < mind + delta:
            if i < delta:
                # N quadrant
                return None, _rotb2b(i, j - delta)
            elif i < maxd - delta:
                # C quadrant
                return (i - delta, j), _rotb2b(i, j - delta)
            else:
                # S quadrant
                return None, _rotb2b(i, j - delta)
        else:
            # E quadrant
            if not (delta <= i < delta + mind):
                return None, None
            else:
                return (i - delta, j), None

    return composed, f


def argmax(composed: np.ndarray) -> tuple[int, int]:
    """Find indices of maximum value in array.

    Args:
        composed: Input array to search

    Returns:
        Tuple of (row, col) indices of maximum value
    """
    return tuple(np.unravel_index(np.argmax(composed), composed.shape))

================
File: iros/io.py
================
from functools import cached_property
from pathlib import Path
from dataclasses import dataclass

from astropy.io import fits
from astropy.io.fits.fitsrec import FITS_rec
from astropy.io.fits.header import Header


def _get_simulation_fits_data(filedict: dict, kind: str, headers: bool = False) -> dict:
    """
    Load data or headers from FITS simulation files for both WFM cameras.

    Args:
        filedict: Dictionary containing file paths for both cameras (i.e., Dataloader.simulation_files)
        kind: Type of data to load ('detected', 'reconstructed', or 'sources')
        headers: If True, return headers instead of data

    Returns:
        Dictionary mapping camera IDs to their respective data or headers
    """

    def fits2data(f: Path, headers: bool):
        data, header = fits.getdata(f, ext=1, header=True)
        if headers:
            return header
        return data

    return {k: fits2data(filedict[k][kind], headers) for k in ["cam1a", "cam1b"]}


@dataclass(frozen=True)
class SimulationDataLoader:
    """
    An immutable dataclass for loading WFM simulation data from FITS files.

    The class handles data from two cameras (cam1a and cam1b), each containing detected,
    reconstructed, and source data. It provides access to both the data and headers of
    these files, as well as pointing information for the cameras in those simulations.

    Attributes:
        root: Path to root directory containing the simulation data files
    """

    root: Path

    @cached_property
    def simulation_files(self):
        """
        Locate and validate all required FITS files in the root directory.

        Returns:
            Nested dictionary mapping camera IDs to their respective file paths
            for detected, reconstructed, and source data.

        Raises:
            ValueError: If expected files are missing or if multiple matches are found
        """

        def check_and_pick(parent: Path, pattern: str) -> Path:
            matches = tuple(parent.glob(pattern))
            if not matches:
                raise ValueError(f"A file matching the pattern {str(parent / pattern)} is expected but missing.")
            f, *extra_matches = matches
            if extra_matches:
                raise ValueError(f"Found unexpected extra matches for glob pattern {str(parent / pattern)}." f"File with pattern {pattern} should be unique")
            return f

        return {
            "cam1a": {
                "detected": check_and_pick(self.root, "cam1a/*detected_plane.fits"),
                "reconstructed": check_and_pick(self.root, "cam1a/*reconstructed.fits"),
                "sources": check_and_pick(self.root, "cam1a/*sources.fits"),
            },
            "cam1b": {
                "detected": check_and_pick(self.root, "cam1b/*detected_plane.fits"),
                "reconstructed": check_and_pick(self.root, "cam1b/*reconstructed.fits"),
                "sources": check_and_pick(self.root, "cam1b/*sources.fits"),
            },
        }

    @cached_property
    def pointings(self) -> dict[str, dict[str, tuple]]:
        """
        Extract camera pointing information from reconstruction file headers.

        Returns:
            Nested dictionary containing RA/Dec coordinates for both cameras'
            z and x axes.
        """
        header_1a = fits.getheader(self.simulation_files["cam1a"]["reconstructed"], ext=0)
        header_1b = fits.getheader(self.simulation_files["cam1b"]["reconstructed"], ext=0)
        return {
            "cam1a": {
                "radec_z": (header_1a["CAMZRA"], header_1a["CAMZDEC"]),
                "radec_x": (header_1a["CAMXRA"], header_1a["CAMXDEC"]),
            },
            "cam1b": {
                "radec_z": (header_1b["CAMZRA"], header_1b["CAMZDEC"]),
                "radec_x": (header_1b["CAMXRA"], header_1b["CAMXDEC"]),
            },
        }

    @property
    def detected(self) -> dict[str, FITS_rec]:
        """
        Load photons data without plane position reconstruction effects from both cameras.

        Returns:
            Dictionary mapping camera IDs to their detected plane data arrays
        """
        return _get_simulation_fits_data(self.simulation_files, "detected", headers=False)

    @property
    def reconstructed(self) -> dict[str, FITS_rec]:
        """
        Load reconstructed photons data from both cameras.

        Returns:
            Dictionary mapping camera IDs to their reconstructed data arrays
        """
        return _get_simulation_fits_data(self.simulation_files, "reconstructed", headers=False)

    @property
    def source(self) -> dict[str, FITS_rec]:
        """
        Load source data from both cameras.

        Returns:
            Dictionary mapping camera IDs to their source data arrays
        """
        return _get_simulation_fits_data(self.simulation_files, "sources", headers=False)

    @property
    def header_detected(self) -> dict[str, Header]:
        """
        Load FITS headers from detected plane files for both cameras.

        Returns:
            Dictionary mapping camera IDs to their detected plane headers
        """
        return _get_simulation_fits_data(self.simulation_files, "detected", headers=True)

    @property
    def header_reconstructed(self) -> dict[str, Header]:
        """
        Load FITS headers from reconstructed files for both cameras.

        Returns:
            Dictionary mapping camera IDs to their reconstructed data headers
        """
        return _get_simulation_fits_data(self.simulation_files, "reconstructed", headers=True)

    @property
    def header_source(self) -> dict[str, Header]:
        """
        Load FITS headers from source files for both cameras.

        Returns:
            Dictionary mapping camera IDs to their source data headers
        """
        return _get_simulation_fits_data(self.simulation_files, "sources", headers=True)


def fetch_simulation(data_root: str | Path):
    return SimulationDataLoader(Path(data_root))


@dataclass(frozen=True)
class MaskDataLoader:
    """
    Frozen dataclass for loading and parsing mask-related FITS data from a single file.
    Handles mask parameters and various data extensions (mask, decoder, and bulk data).

    Attributes:
        filepath: path to mask file
    """

    filepath: Path

    def __getitem__(self, key: str) -> float:
        """Access mask parameters via dictionary-style lookup."""
        return self.parameters[key]

    @cached_property
    def parameters(self) -> dict[str, float]:
        """
        Extract and convert mask parameters from FITS headers (extensions 0 and 2).

        Returns:
            Dictionary of mask parameters (dimensions, bounds, distances) as float values
        """
        h = dict(fits.getheader(self.filepath, ext=0)) | dict(fits.getheader(self.filepath, ext=2))
        return {
            k: float(v)
            for k, v in {
                "mask_minx": h["MINX"],
                "mask_miny": h["MINY"],
                "mask_maxx": h["MAXX"],
                "mask_maxy": h["MAXY"],
                "mask_deltax": h["ELXDIM"],
                "mask_deltay": h["ELYDIM"],
                "detector_minx": h["PLNXMIN"],
                "detector_maxx": h["PLNXMAX"],
                "detector_miny": h["PLNYMIN"],
                "detector_maxy": h["PLNYMAX"],
                "mask_detector_distance": h["MDDIST"],
            }.items()
        }

    @property
    def mask(self) -> fits.FITS_rec:
        """
        Load mask data from mask FITS file.

        Returns:
            FITS record array containing mask data
        """
        return fits.getdata(self.filepath, ext=2)

    @property
    def decoder(self) -> fits.FITS_rec:
        """
        Load decoder data from mask FITS file.

        Returns:
            FITS record array containing decoder data
        """
        return fits.getdata(self.filepath, ext=3)

    @property
    def bulk(self) -> fits.FITS_rec:
        """
        Load bulk data from mask FITS file.

        Returns:
            FITS record array containing bulk data
        """
        return fits.getdata(self.filepath, ext=4)

    @property
    def header_mask(self) -> fits.Header:
        """
        Load mask header from mask FITS file.

        Returns:
            FITS header containing mask data
        """
        return fits.getheader(self.filepath, ext=2)

    @property
    def header_decoder(self) -> fits.Header:
        """
        Load decoder header from mask FITS file.

        Returns:
            FITS header containing decoder data
        """
        return fits.getheader(self.filepath, ext=3)

    @property
    def header_bulk(self) -> fits.Header:
        """
        Load bulk header from mask FITS file.

        Returns:
            FITS header containing bulk data
        """
        return fits.getheader(self.filepath, ext=4)


def fetch_mask(filepath: str | Path):
    return MaskDataLoader(Path(filepath))

================
File: iros/mask.py
================
from typing import NamedTuple
from bisect import bisect_left, bisect_right
from functools import cached_property
from dataclasses import dataclass
from pathlib import Path

import numpy as np
from astropy.io.fits.fitsrec import FITS_rec
from scipy.stats import binned_statistic_2d
from scipy.signal import correlate

from .io import MaskDataLoader


class Bins2D(NamedTuple):
    """Two-dimensional binning structure for mask and detector coordinates.

    Args:
        x: Array of x-coordinate bin edges
        y: Array of y-coordinate bin edges
    """
    x: np.array
    y: np.array


def _bin(
    start: float,
    stop: float,
    step: float,
) -> tuple[np.array, np.array]:
    """Returns equally spaced points between start and stop, included.

    Args:
        start: Minimum x-coordinate
        stop: Minimum y-coordinate
        step: Maximum x-coordinate

    Returns:
        Bin edges array.
    """
    return np.linspace(start, stop, int((stop - start) / step) + 1)


class UpscaleFactor(NamedTuple):
    """Upscaling factors for x and y dimensions.

    Args:
        x: Upscaling factor for x dimension
        y: Upscaling factor for y dimension
    """
    x: int
    y: int


def _upscale(
    m: np.ndarray,
    upscale_f: UpscaleFactor,
) -> np.ndarray:
    """Upscale a 2D array by repeating elements along each axis.

    Args:
        m: Input 2D array
        upscale_f: UpscaleFactor containing scaling factors for each dimension

    Returns:
        Upscaled array with dimensions multiplied by respective scaling factors
    """
    fx, fy = upscale_f.x, upscale_f.y
    # VERY careful here, the next is not a typo.
    # if i'm upscaling by (2, 1). it means i'm doubling the elements
    # over the x direction, while keeping the same element over the y direction.
    # this means doubling the number of columns in the mask array, while
    # keeping the number of rows the same.
    m = np.repeat(m, fy, axis=0)
    m = np.repeat(m, fx, axis=1)
    return m


def _fold(ml: FITS_rec, mask_bins: Bins2D,) -> np.array:
    """Convert mask data from FITS record to 2D binned array.

    Args:
        ml: FITS record containing mask data
        mask_bins: Binning structure for the mask

    Returns:
        2D array containing binned mask data
    """
    return binned_statistic_2d(ml["X"], ml["Y"], ml["VAL"], statistic="max", bins=[mask_bins.x, mask_bins.y])[0].T


def _resize(a: np.array, b: np.array,) -> np.array:
    """Resizes the `a` matrix to the size of the smallest submatrix of `b` with non-zero border"

    Args:
        a: Array to be resized
        b: Reference array defining the non-zero border

    Returns:
        Resized submatrix of input array
    """
    non_zero_rows = np.where(b.any(axis=1))[0]
    non_zero_cols = np.where(b.any(axis=0))[0]
    row_start, row_end = non_zero_rows[0], non_zero_rows[-1] + 1
    col_start, col_end = non_zero_cols[0], non_zero_cols[-1] + 1
    submatrix = a[row_start:row_end, col_start:col_end]
    return submatrix


def bisect_interval(a: np.array, start: float, stop: float):
    """
    Given a monotonically increasing array of floats and a float interval (start, stop)
    in it, returns the indices of the smallest sub array containing the interval.

    Args:
        a (np.array): A monotonically increasing array of floats.
        start (float): The lower bound of the interval. Must be greater than or equal to
            the first element of the array.
        stop (float): The upper bound of the interval. Must be less than or equal to
            the last element of the array.

    Returns:
        tuple: A pair of integers (left_idx, right_idx) where:
            - left_idx is the index of the largest value in 'a' that is less than or equal to 'start'
            - right_idx is the index of the smallest value in 'a' that is greater than or equal to 'stop'

    Raises:
        ValueError: If the interval [start, stop] is not contained within the array bounds
            or if the input array is not monotonically increasing.
    """
    if not (start >= a[0] and stop <= a[-1]):
        raise ValueError("The interval isn't contained in the input array")
    if not np.all(np.diff(a) > 0):
        raise ValueError("The array isn't monotonically increasing")
    return bisect_right(a, start) - 1, bisect_left(a, stop)


@dataclass(frozen=True)
class CodedMaskCamera:
    """Class representing a coded mask camera system.

    Handles mask pattern, detector geometry, and related calculations for coded mask imaging.

    Args:
        mdl: Mask data loader object containing mask and detector specifications
        upscale_f: Tuple of upscaling factors for x and y dimensions

    Raises:
        ValueError: If detector plane is larger than mask or if upscale factors are not positive
    """
    mdl: MaskDataLoader
    upscale_f: UpscaleFactor

    def _bins_mask(self, upscale_f: UpscaleFactor, ) -> Bins2D:
        """Generate binning structure for mask with given upscale factors."""
        return Bins2D(
            _bin(self.mdl["mask_minx"], self.mdl["mask_maxx"], self.mdl["mask_deltax"] / upscale_f.x),
            _bin(self.mdl["mask_miny"], self.mdl["mask_maxy"], self.mdl["mask_deltay"] / upscale_f.y),
        )

    @property
    def bins_mask(self) -> Bins2D:
        """Binning structure for the mask pattern."""
        return self._bins_mask(self.upscale_f)

    def _bins_detector(self, upscale_f: UpscaleFactor) -> Bins2D:
        """Generate binning structure for detector with given upscale factors."""
        bins = self._bins_mask(self.upscale_f)
        xmin, xmax = bisect_interval(bins.x, self.mdl["detector_minx"], self.mdl["detector_maxx"])
        ymin, ymax = bisect_interval(bins.y, self.mdl["detector_miny"], self.mdl["detector_maxy"])
        return Bins2D(
            _bin(bins.x[xmin], bins.x[xmax], self.mdl["mask_deltax"] / upscale_f.x),
            _bin(bins.y[ymin], bins.y[ymax], self.mdl["mask_deltay"] / upscale_f.y),
        )

    @property
    def bins_detector(self) -> Bins2D:
        """Binning structure for the detector."""
        return self._bins_detector(self.upscale_f)

    def _bins_sky(self, upscale_f: UpscaleFactor) -> Bins2D:
        """Binning structure for the reconstructed sky image."""
        o, p = self.mask_shape
        bins = self._bins_detector(upscale_f)
        binstep, nbins = bins.x[1] - bins.x[0], o // 2 - 1
        xbins = np.concatenate(
            (
                np.linspace(bins.x[0] - (nbins + 1) * binstep, bins.x[-0] - binstep, nbins + 1),
                bins.x,
                np.linspace(bins.x[-1] + binstep, bins.x[-1] + nbins * binstep, nbins),
            )
        )
        binstep, nbins = bins.y[1] - bins.y[0], p // 2 - 1
        ybins = np.concatenate(
            (
                np.linspace(bins.y[0] - (nbins + 1) * binstep, bins.y[-0] - binstep, nbins + 1),
                bins.y,
                np.linspace(bins.y[-1] + binstep, bins.y[-1] + nbins * binstep, nbins),
            )
        )
        return Bins2D(x=xbins, y=ybins)

    @property
    def bins_sky(self) -> Bins2D:
        return self._bins_sky(self.upscale_f)

    @cached_property
    def mask(self) -> np.array:
        """2D array representing the coded mask pattern."""
        return _upscale(_fold(self.mdl.mask, self._bins_mask(UpscaleFactor(1, 1))).astype(int), self.upscale_f)

    @cached_property
    def decoder(self) -> np.array:
        """2D array representing the mask pattern used for decoding."""
        return _upscale(_fold(self.mdl.decoder, self._bins_mask(UpscaleFactor(1, 1))), self.upscale_f)

    @cached_property
    def bulk(self) -> np.array:
        """2D array representing the bulk (sensitivity) array of the mask."""
        framed_bulk = _fold(self.mdl.bulk, self._bins_mask(UpscaleFactor(1, 1)))
        framed_bulk[~np.isclose(framed_bulk, np.zeros_like(framed_bulk))] = 1
        bins = self._bins_mask(self.upscale_f)
        xmin, xmax = bisect_interval(bins.x, self.mdl["detector_minx"], self.mdl["detector_maxx"])
        ymin, ymax = bisect_interval(bins.y, self.mdl["detector_miny"], self.mdl["detector_maxy"])
        return _upscale(framed_bulk, self.upscale_f)[ymin:ymax, xmin:xmax]

    @cached_property
    def balancing(self) -> np.array:
        """2D array representing the correlation between decoder and bulk patterns."""
        return correlate(self.decoder, self.bulk, mode="full")

    @property
    def detector_shape(self) -> tuple[int, int]:
        """Shape of the detector array (rows, columns)."""
        xmin = np.floor(self.mdl["detector_minx"] / (self.mdl["mask_deltax"] / self.upscale_f.x))
        xmax = np.ceil(self.mdl["detector_maxx"] / (self.mdl["mask_deltax"] / self.upscale_f.x))
        ymin = np.floor(self.mdl["detector_miny"] / (self.mdl["mask_deltay"] / self.upscale_f.y))
        ymax = np.ceil(self.mdl["detector_maxy"] / (self.mdl["mask_deltay"] / self.upscale_f.y))
        return int(ymax - ymin), int(xmax - xmin)

    @property
    def mask_shape(self) -> tuple[int, int]:
        """Shape of the mask array (rows, columns)."""
        return (
            int((self.mdl["mask_maxy"] - self.mdl["mask_miny"]) / (self.mdl["mask_deltay"] / self.upscale_f.y)),
            int((self.mdl["mask_maxx"] - self.mdl["mask_minx"]) / (self.mdl["mask_deltax"] / self.upscale_f.x)),
        )

    @property
    def sky_shape(self) -> tuple[int, int]:
        """Shape of the reconstructed sky image (rows, columns)."""
        n, m = self.detector_shape
        o, p = self.mask_shape
        return n + o - 1, m + p - 1


def fetch_camera(
    mask_filepath: str | Path,
    upscale_f: tuple[int, int] = (1, 1),
) -> CodedMaskCamera:
    """
    An interface to CodedMaskCamera.

    Args:
        mask_filepath: a str or a path object pointing to the mask filepath
        upscale_f: the upscaling factor in x and y coordinates

    Returns: a CodedMaskCamera object.

    """
    # guarantee that the bisect operation just below are performed on well suited arrays.
    mdl = MaskDataLoader(mask_filepath)

    if not (
        # fmt: off
        mdl["detector_minx"] >= mdl["mask_minx"] and
        mdl["detector_maxx"] <= mdl["mask_maxx"] and
        mdl["detector_miny"] >= mdl["mask_miny"] and
        mdl["detector_maxy"] <= mdl["mask_maxy"]
        # fmt: on
    ):
        raise ValueError("Detector plane is larger than mask.")

    if not (upscale_f[0] > 0 and upscale_f[1] > 0):
        raise ValueError("Upscale factors must be positive integers.")

    return CodedMaskCamera(mdl, UpscaleFactor(*upscale_f))


def encode(camera: CodedMaskCamera, sky: np.ndarray) -> np.array:
    """Generate detector shadowgram from sky image through coded mask.

    Args:
        camera: CodedMaskCamera object containing mask pattern
        sky: 2D array representing sky image

    Returns:
        2D array representing detector shadowgram
    """
    unnormalized_shadowgram = correlate(camera.mask, sky, mode="valid")
    return unnormalized_shadowgram


def decode(camera: CodedMaskCamera, detector: np.array) -> tuple[np.array, np.array]:
    """Reconstruct balanced sky image from detector counts using cross-correlation.

    Args:
        camera: CodedMaskCamera object containing mask and decoder patterns
        detector: 2D array of detector counts

    Returns:
        Tuple containing:
            - Balanced cross-correlation sky image
            - Variance map of the reconstructed sky image
    """
    cc = correlate(camera.decoder, detector, mode="full")
    var = correlate(np.square(camera.decoder), detector, mode="full")
    sum_det, sum_bulk = map(np.sum, (detector, camera.bulk))
    cc_bal = cc - camera.balancing * sum_det / sum_bulk
    var_bal = var + np.square(camera.balancing) * sum_det / np.square(sum_bulk) ** 2 - 2 * cc * camera.balancing / sum_bulk
    return cc_bal, var_bal


def psf(camera: CodedMaskCamera) -> np.array:
    """Calculate Point Spread Function (PSF) of the coded mask system.

    Args:
        camera: CodedMaskCamera object containing mask and decoder patterns

    Returns:
        2D array representing the system's PSF
    """
    return correlate(camera.mask, camera.decoder, mode="same")


def count(camera, data):
    """Create 2D histogram of detector counts from event data.

    Args:
        camera: CodedMaskCamera object containing detector binning
        data: Array of event data with `X` and `Y` coordinates

    Returns:
        2D array of binned detector counts
    """
    bins = camera.bins_detector
    counts, *_ = np.histogram2d(data["Y"], data["X"], bins=[bins.y, bins.x])
    return counts

================
File: iros/utils.py
================
from contextlib import (
    contextmanager,
)


@contextmanager
def catchtime(
    label: str
) -> Callable[[], float]:
    """A context manager for measuring processing times."""
    t1 = t2 = perf_counter()
    yield lambda: t2 - t1
    t2 = perf_counter()
    print(f"{label} took {t2 - t1:.7}s")

================
File: package.json
================
{
  "dependencies": {
    "repomix": "^0.2.5"
  }
}

================
File: pyproject.toml
================
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "iros"
version = "0.0.1"
authors = [
    { name="Giuseppe Dilillo", email="peppedilillo@gmail.com" },
]
requires-python = ">=3.12"
classifiers = [
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.12",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
]
dependencies = [
    "numpy",
	"pandas",
    "matplotlib",
    "astropy",
    "scipy",
]

[project.optional-dependencies]
dev = [
    "black",
    "isort",
    "ipython",
    "jupyter",
]

================
File: README.md
================
This is a sandbox for playing with simple simulations of coded aperture instruments. Work in progres.

To install, clone the repo and `pip install '.[dev]'` it.

================
File: tests/test_image_composition.py
================
import unittest

import numpy as np

from iros.images import compose


class TestCompose(unittest.TestCase):
    def setUp(self):
        self.a_2x4 = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])
        self.b_2x4 = np.array([[9, 10, 11, 12], [13, 14, 15, 16]])
        self.a_2x2 = np.array([[1, 2], [3, 4]])
        self.b_2x2 = np.array([[1, 3], [2, 4]])

    def test_compose_rectangular(self):
        composed, f = compose(self.a_2x4, self.b_2x4)
        self.assertEqual(composed.shape, (4, 4))

        pos_a, pos_b = f(1, 1)
        self.assertEqual(pos_a, (0, 1))
        self.assertEqual(pos_b, (1, 1))

        expected = np.array([
            [0,  13, 9,  0],
            [1, 2+14, 3+10, 4],
            [5, 6+15, 7+11, 8],
            [0, 16, 12,  0]
        ])
        np.testing.assert_array_equal(composed, expected)

    def test_compose_square(self):
        composed, f = compose(self.a_2x2, self.b_2x2)

        pos_a, pos_b = f(0, 0)
        self.assertEqual(pos_a, (0, 0))
        self.assertEqual(pos_b, (1, 0))

        expected = np.array([
            [1+2, 2+1],
            [3+4, 4+3],
        ])
        np.testing.assert_array_equal(composed, expected)

    def test_compose_mapping(self):
        _, f = compose(self.a_2x4, self.b_2x4)

        # Test W region (left)
        self.assertEqual(f(1, 0), ((0, 0), None))

        # Test E region (right)
        self.assertEqual(f(1, 3), ((0, 3), None))

        # Test N region (top)
        self.assertEqual(f(0, 1), (None, (1, 0)))

        # Test S region (bottom)
        self.assertEqual(f(3, 1), (None, (1, 3)))

        # Test corners
        self.assertEqual(f(0, 0), (None, None))
        self.assertEqual(f(0, 3), (None, None))
        self.assertEqual(f(3, 0), (None, None))
        self.assertEqual(f(3, 3), (None, None))

================
File: tests/test_mask_camera.py
================
import unittest

import numpy as np

from iros.mask import fetch_camera, encode, decode, psf, bisect_interval
from iros.assets import path_wfm_mask


class TestWFM(unittest.TestCase):
    def setUp(self):
        self.wfm = fetch_camera(path_wfm_mask, (2, 1))

    def test_shape_bulk(self):
        self.assertEqual(self.wfm.bulk.shape, self.wfm.detector_shape)

    def test_shape_detector(self):
        self.assertFalse(self.wfm.detector_shape == self.wfm.mask_shape)

    def test_sky_bins(self):
        xbins, ybins = self.wfm._bins_sky(self.wfm.upscale_f)
        assert len(np.unique(xbins)) == len(xbins)
        assert len(np.unique(ybins)) == len(ybins)
        assert len(np.unique(np.round(np.diff(xbins), 7))) == 1
        assert len(np.unique(np.round(np.diff(ybins), 7))) == 1

    def test_encode_shape(self):
        sky = np.zeros(self.wfm.sky_shape)
        self.assertEqual(encode(self.wfm, sky).shape, self.wfm.detector_shape)

    def test_encode_decode(self):
        n, m = self.wfm.sky_shape
        sky = np.zeros((n, m))
        sky[n // 2, m // 2] = 10000
        detector = encode(self.wfm, sky)
        decoded_sky, _ = decode(self.wfm, detector)
        self.assertTrue(np.any(decoded_sky))

    def test_decode_shape(self):
        detector = np.zeros(self.wfm.detector_shape)
        cc, var = decode(self.wfm, detector)
        cc_b, var_b = decode(self.wfm, detector)
        self.assertEqual(cc.shape, self.wfm.sky_shape)
        self.assertEqual(cc_b.shape, self.wfm.sky_shape)
        self.assertEqual(var.shape, self.wfm.sky_shape)
        self.assertEqual(var_b.shape, self.wfm.sky_shape)

    def test_psf_shape(self):
        self.assertEqual(psf(self.wfm).shape, self.wfm.mask_shape)

    # this may take some time
    @unittest.skip
    def test_all_sources_projects(self):
        n, m = self.wfm.sky_shape()
        for i in range(n):
            for j in range(m):
                sky = np.zeros(self.wfm.sky_shape())
                sky[i, j] = 1
                self.assertTrue(np.any(self.wfm.encode(sky)))


class TestBisectInterval(unittest.TestCase):
    def setUp(self):
        # Create a simple monotonic array for testing
        self.arr = np.array([1.0, 2.0, 3.0, 4.0, 5.0])

    def test_normal_case(self):
        """Test with an interval fully within the array bounds"""
        result = bisect_interval(self.arr, 2.5, 3.5)
        self.assertEqual(result, (1, 3))

    def test_exact_bounds(self):
        """Test when interval bounds exactly match array elements"""
        result = bisect_interval(self.arr, 2.0, 4.0)
        self.assertEqual(result, (1, 3))

    def test_single_point_interval(self):
        """Test when start and stop are the same"""
        result = bisect_interval(self.arr, 3.0, 3.0)
        self.assertEqual(result, (2, 2))

    def test_boundary_case(self):
        """Test with interval at array boundaries"""
        result = bisect_interval(self.arr, 1.0, 5.0)
        self.assertEqual(result, (0, 4))

    def test_invalid_interval_below(self):
        """Test with interval starting below array bounds"""
        with self.assertRaises(ValueError):
            bisect_interval(self.arr, 0.5, 3.0)

    def test_invalid_interval_above(self):
        """Test with interval ending above array bounds"""
        with self.assertRaises(ValueError):
            bisect_interval(self.arr, 2.0, 5.5)

    def test_non_monotonic_array(self):
        """Test with non-monotonic array"""
        non_monotonic = np.array([1.0, 3.0, 2.0, 4.0, 5.0])
        with self.assertRaises(ValueError):
            bisect_interval(non_monotonic, 2.0, 3.0)
